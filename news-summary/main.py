import dotenv
dotenv.load_dotenv()

import yaml
import re
from datetime import datetime, timedelta
from pathlib import Path
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
from crewai.tools import tool
from crewai import Crew, Agent, Task
from crewai.project import CrewBase, agent, task, crew


def is_video_article(title: str, link: str) -> bool:
    """ë™ì˜ìƒ ê¸°ì‚¬ì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    if not title:
        return False
    
    title_lower = title.lower()
    link_lower = link.lower()
    
    # ì œëª©ì— ë™ì˜ìƒ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    video_keywords = ['ë™ì˜ìƒ', 'ì˜ìƒ', 'video', 'tv', 'ë°©ì†¡']
    if any(keyword in title_lower for keyword in video_keywords):
        return True
    
    # ë§í¬ì— ë™ì˜ìƒ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    if any(keyword in link_lower for keyword in ['video', 'tv', 'broadcast']):
        return True
    
    return False


def parse_date(date_str: str) -> Optional[datetime]:
    """ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
    if not date_str or date_str == "ë‚ ì§œ ì—†ìŒ":
        return None
    
    date_str = date_str.strip()
    
    # ìƒëŒ€ì  ì‹œê°„ í‘œí˜„ ì²˜ë¦¬ (ì˜ˆ: "1ì‹œê°„ ì „", "2ì¼ ì „", "ë°©ê¸ˆ")
    relative_patterns = [
        (r'(\d+)\s*ë¶„\s*ì „', 'minutes'),
        (r'(\d+)\s*ì‹œê°„\s*ì „', 'hours'),
        (r'(\d+)\s*ì¼\s*ì „', 'days'),
        (r'ë°©ê¸ˆ', 'now'),
    ]
    
    for pattern, unit in relative_patterns:
        match = re.search(pattern, date_str)
        if match:
            now = datetime.now()
            if unit == 'now':
                return now
            elif unit == 'minutes':
                minutes_ago = int(match.group(1))
                return now - timedelta(minutes=minutes_ago)
            elif unit == 'hours':
                hours_ago = int(match.group(1))
                return now - timedelta(hours=hours_ago)
            elif unit == 'days':
                days_ago = int(match.group(1))
                return now - timedelta(days=days_ago)
    
    # ì ˆëŒ€ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
    date_formats = [
        '%Y.%m.%d',           # 2024.01.15
        '%Y-%m-%d',           # 2024-01-15
        '%Y/%m/%d',           # 2024/01/15
        '%Y.%m.%d %H:%M',     # 2024.01.15 14:30
        '%Y-%m-%d %H:%M',     # 2024-01-15 14:30
        '%Y.%m.%d %H:%M:%S',  # 2024.01.15 14:30:00
        '%Yë…„ %mì›” %dì¼',     # 2024ë…„ 1ì›” 15ì¼
        '%Y.%m.%d %H:%M:%S',  # 2024.01.15 14:30:00
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    # ì •ê·œì‹ìœ¼ë¡œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
    date_pattern = r'(\d{4})[.\-/](\d{1,2})[.\-/](\d{1,2})'
    match = re.search(date_pattern, date_str)
    if match:
        year, month, day = match.groups()
        try:
            return datetime(int(year), int(month), int(day))
        except ValueError:
            pass
    
    return None


def is_within_week(date_str: str) -> bool:
    """ë‚ ì§œê°€ ìµœê·¼ ì¼ì£¼ì¼ ì´ë‚´ì¸ì§€ í™•ì¸"""
    parsed_date = parse_date(date_str)
    if parsed_date is None:
        # ë‚ ì§œë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìœ¼ë©´ í¬í•¨ (ì•ˆì „í•œ ì„ íƒ)
        return True
    
    now = datetime.now()
    week_ago = now - timedelta(days=7)
    
    return parsed_date >= week_ago


def _collect_naver_news_impl(category: str, num_articles: int = 5) -> List[Dict]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì§€ì •ëœ ì¹´í…Œê³ ë¦¬ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        category: ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ('ì •ì¹˜' ë˜ëŠ” 'ê²½ì œ')
        num_articles: ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
    
    Returns:
        ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ê° ë‰´ìŠ¤ëŠ” title, link, content, dateë¥¼ í¬í•¨)
    """
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    category_map = {
        'ì •ì¹˜': '100',
        'ê²½ì œ': '101'
    }
    
    if category not in category_map:
        return []
    
    sid = category_map[category]
    news_list = []
    
    try:
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ URL
        url = f"https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1={sid}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = 'utf-8'
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ì—¬ëŸ¬ ì„ íƒìë¡œ ë‰´ìŠ¤ ë§í¬ ì°¾ê¸°
        news_links = []
        seen_links = set()
        
        # ë°©ë²• 1: ul.type06_headline ë˜ëŠ” ul.type06 ì•ˆì˜ dt > a ì°¾ê¸°
        for ul in soup.find_all('ul', class_=lambda x: x and ('type06' in x or 'headline' in x)):
            for li in ul.find_all('li'):
                dt = li.find('dt')
                if dt:
                    a_tag = dt.find('a')
                    if a_tag and a_tag.get('href'):
                        href = a_tag.get('href')
                        title = a_tag.get('title', '') or a_tag.text.strip()
                        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        if href.startswith('/'):
                            href = 'https://news.naver.com' + href
                        elif not href.startswith('http'):
                            continue
                        
                        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ)
                        date = ""
                        date_tag = li.find('span', class_=lambda x: x and ('date' in str(x).lower() or 'time' in str(x).lower()))
                        if not date_tag:
                            date_tag = li.find('dd', class_=lambda x: x and 'date' in str(x).lower())
                        if date_tag:
                            date = date_tag.get_text(strip=True)
                        
                        # ë™ì˜ìƒ ê¸°ì‚¬ ì œì™¸ ë° ìœ íš¨ì„± ê²€ì‚¬
                        if href and title and len(title.strip()) > 5 and not is_video_article(title, href):
                            # ì¤‘ë³µ ì œê±°
                            if href not in seen_links:
                                seen_links.add(href)
                                news_links.append({'title': title.strip(), 'link': href, 'date': date})
                                if len(news_links) >= num_articles:
                                    break
            if len(news_links) >= num_articles:
                break
        
        # ë°©ë²• 2: dt íƒœê·¸ì˜ a ë§í¬ ì°¾ê¸° (ì „ì²´ í˜ì´ì§€)
        if len(news_links) < num_articles:
            for dt in soup.find_all('dt'):
                a_tag = dt.find('a')
                if a_tag and a_tag.get('href'):
                    href = a_tag.get('href')
                    title = a_tag.get('title', '') or a_tag.text.strip()
                    if href.startswith('/'):
                        href = 'https://news.naver.com' + href
                    elif not href.startswith('http'):
                        continue
                    
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì‹œë„
                    date = ""
                    parent = dt.find_parent('li')
                    if parent:
                        date_tag = parent.find('span', class_=lambda x: x and ('date' in str(x).lower() or 'time' in str(x).lower()))
                        if date_tag:
                            date = date_tag.get_text(strip=True)
                    
                    # ë™ì˜ìƒ ê¸°ì‚¬ ì œì™¸ ë° ìœ íš¨ì„± ê²€ì‚¬
                    if href and title and len(title.strip()) > 5 and not is_video_article(title, href):
                        if href not in seen_links:
                            seen_links.add(href)
                            news_links.append({'title': title.strip(), 'link': href, 'date': date})
                            if len(news_links) >= num_articles:
                                break
        
        # ë°©ë²• 3: li._itemì˜ a íƒœê·¸ ì°¾ê¸°
        if len(news_links) < num_articles:
            for li in soup.find_all('li', class_='_item'):
                a_tag = li.find('a')
                if a_tag and a_tag.get('href'):
                    href = a_tag.get('href')
                    title = a_tag.get('title', '') or a_tag.text.strip()
                    if href.startswith('/'):
                        href = 'https://news.naver.com' + href
                    elif not href.startswith('http'):
                        continue
                    
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    date = ""
                    date_tag = li.find('span', class_=lambda x: x and ('date' in str(x).lower() or 'time' in str(x).lower()))
                    if date_tag:
                        date = date_tag.get_text(strip=True)
                    
                    # ë™ì˜ìƒ ê¸°ì‚¬ ì œì™¸ ë° ìœ íš¨ì„± ê²€ì‚¬
                    if href and title and len(title.strip()) > 5 and not is_video_article(title, href):
                        if href not in seen_links:
                            seen_links.add(href)
                            news_links.append({'title': title.strip(), 'link': href, 'date': date})
                            if len(news_links) >= num_articles:
                                break
        
        # ì¼ì£¼ì¼ ì´ë‚´ ê¸°ì‚¬ë§Œ í•„í„°ë§ (ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ ë‚ ì§œê°€ ìˆëŠ” ê²½ìš°)
        # ë‚ ì§œê°€ ì—†ê±°ë‚˜ ì¼ì£¼ì¼ ì´ë‚´ì¸ ê¸°ì‚¬ë§Œ í¬í•¨
        filtered_news = []
        for news_item in news_links:
            date = news_item.get('date', '')
            # ë‚ ì§œê°€ ì—†ê±°ë‚˜ ì¼ì£¼ì¼ ì´ë‚´ì¸ ê²½ìš° í¬í•¨ (ë‚ ì§œê°€ ì—†ìœ¼ë©´ ë‚˜ì¤‘ì— ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ í™•ì¸)
            if not date or is_within_week(date):
                filtered_news.append(news_item)
        
        # í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸° (í•„í„°ë§ í›„ì—ë„ ì¶©ë¶„í•œ ê¸°ì‚¬ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•´ ë” ë§ì´ ìˆ˜ì§‘)
        unique_news = filtered_news[:num_articles * 2]  # ì—¬ìœ ìˆê²Œ ìˆ˜ì§‘
        
        # ê° ë‰´ìŠ¤ì˜ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
        for news_item in unique_news:
            title = news_item['title']
            link = news_item['link']
            date = news_item.get('date', '')  # ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë‚ ì§œ
            content = ""
            
            try:
                article_response = requests.get(link, headers=headers, timeout=10)
                article_response.raise_for_status()
                article_response.encoding = 'utf-8'
                article_soup = BeautifulSoup(article_response.content, 'html.parser')
                
                # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ, ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ ëª» ê°€ì ¸ì˜¨ ê²½ìš°)
                if not date:
                    # ì—¬ëŸ¬ ë‚ ì§œ ì„ íƒì ì‹œë„
                    date_selectors = [
                        ('span', {'class': 't11'}),
                        ('span', {'class': '_article_date'}),
                        ('div', {'class': 'article_info'}),
                        ('span', {'class': 'date'}),
                        ('div', {'class': 'press_date'}),
                    ]
                    
                    for tag, attrs in date_selectors:
                        date_tag = article_soup.find(tag, attrs)
                        if date_tag:
                            date = date_tag.get_text(strip=True)
                            if date:
                                break
                    
                    # data-module="ArticleBody" ë‚´ë¶€ì˜ ë‚ ì§œ ì°¾ê¸°
                    if not date:
                        article_info = article_soup.find('div', class_=lambda x: x and isinstance(x, str) and ('info' in x.lower() or 'date' in x.lower()))
                        if article_info:
                            date_text = article_info.get_text(strip=True)
                            # ë‚ ì§œ í˜•ì‹ ì¶”ì¶œ (YYYY.MM.DD ë˜ëŠ” YYYY-MM-DD ë“±)
                            date_pattern = r'\d{4}[.\-/]\d{1,2}[.\-/]\d{1,2}'
                            match = re.search(date_pattern, date_text)
                            if match:
                                date = match.group()
                
                # ë³¸ë¬¸ ì°¾ê¸° - ì—¬ëŸ¬ ì„ íƒì ì‹œë„
                article_body = None
                
                # ìµœì‹  ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ì„ íƒìë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
                selectors = [
                    ('div', {'id': 'articleBodyContents'}),
                    ('div', {'id': 'newsEndContents'}),
                    ('div', {'id': 'articeBody'}),
                    ('article', {'id': 'dic_area'}),
                    ('div', {'class': '_article_body_contents'}),
                    ('div', {'class': 'go_trans _article_content'}),
                    ('div', {'id': 'articleBody'}),
                ]
                
                for tag, attrs in selectors:
                    article_body = article_soup.find(tag, attrs)
                    if article_body:
                        break
                
                # ì¼ë°˜ì ì¸ ë³¸ë¬¸ ì˜ì—­ ì°¾ê¸°
                if not article_body:
                    # data-module="ArticleBody" ì†ì„±ì„ ê°€ì§„ div ì°¾ê¸°
                    article_body = article_soup.find('div', {'data-module': 'ArticleBody'})
                
                if not article_body:
                    # classì— article, body, contentê°€ í¬í•¨ëœ div ì°¾ê¸°
                    article_body = article_soup.find('div', class_=lambda x: x and isinstance(x, str) and ('article' in x.lower() or 'body' in x.lower() or 'content' in x.lower()))
                
                if article_body:
                    # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼, ê´‘ê³  ì œê±°
                    for element in article_body.find_all(['script', 'style', 'iframe', 'noscript', 'button']):
                        element.decompose()
                    
                    # ë¶ˆí•„ìš”í•œ í´ë˜ìŠ¤ ì œê±° (ê´‘ê³ , ì¶”ì²œ ê¸°ì‚¬ ë“±)
                    for ad in article_body.find_all(class_=lambda x: x and isinstance(x, str) and ('ad' in x.lower() or 'advertisement' in x.lower() or 'promotion' in x.lower() or 'recommend' in x.lower() or 'related' in x.lower())):
                        ad.decompose()
                    
                    # ë¶ˆí•„ìš”í•œ ì†ì„± ì œê±°
                    for br in article_body.find_all('br'):
                        br.replace_with(' ')
                    
                    content = article_body.get_text(strip=True, separator=' ')
                    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
                    content = ' '.join(content.split())
                    
                    # ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ (20ì ë¯¸ë§Œ) ë³¸ë¬¸ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
                    if len(content) < 20:
                        content = ""
                    
            except Exception as e:
                content = f"ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            
            if not title or len(title.strip()) < 5:
                # ì œëª©ì´ ì—†ìœ¼ë©´ ë§í¬ì—ì„œ ì¶”ì¶œ ì‹œë„
                title = link.split('/')[-1].split('?')[0] if '/' in link else "ì œëª© ì—†ìŒ"
            
            # ë³¸ë¬¸ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ë³¸ë¬¸ ì—†ìŒìœ¼ë¡œ í‘œì‹œ
            if not content or len(content.strip()) < 20:
                content = "ë³¸ë¬¸ ì—†ìŒ"
            else:
                # ë³¸ë¬¸ì´ ìˆìœ¼ë©´ ì²˜ìŒ 1000ìë§Œ ì‚¬ìš©
                content = content[:1000]
            
            # ë‚ ì§œ ì •ë¦¬
            date = date.strip() if date else "ë‚ ì§œ ì—†ìŒ"
            
            # ì¼ì£¼ì¼ ì´ë‚´ ê¸°ì‚¬ë§Œ í¬í•¨
            if is_within_week(date):
                news_list.append({
                    'title': title.strip(),
                    'link': link,
                    'content': content,
                    'date': date
                })
        
    except Exception as e:
        return [{'error': f'ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}]
    
    return news_list


@tool("ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë„êµ¬")
def collect_naver_news(category: str, num_articles: int = 5) -> List[Dict]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì§€ì •ëœ ì¹´í…Œê³ ë¦¬ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        category: ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ('ì •ì¹˜' ë˜ëŠ” 'ê²½ì œ')
        num_articles: ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
    
    Returns:
        ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ê° ë‰´ìŠ¤ëŠ” title, link, content, dateë¥¼ í¬í•¨)
    """
    return _collect_naver_news_impl(category, num_articles)


@CrewBase
class NewsSummaryCrew:
    
    def __init__(self):
        config_path = Path(__file__).parent / "config"
        with open(config_path / "agents.yaml") as f:
            agents_config = yaml.safe_load(f)
        with open(config_path / "tasks.yaml") as f:
            tasks_config = yaml.safe_load(f)
        self.agents_config = agents_config
        self.tasks_config = tasks_config
    
    @agent
    def news_collector_agent(self):
        return Agent(
            **self.agents_config["news_collector_agent"],
            tools=[collect_naver_news],
            verbose=True
        )
    
    @agent
    def news_summarizer_agent(self):
        return Agent(
            **self.agents_config["news_summarizer_agent"],
            verbose=True
        )
    
    @task
    def collect_politics_news_task(self):
        task_config = self.tasks_config["collect_politics_news_task"].copy()
        task_config.pop("agent")
        return Task(
            **task_config,
            agent=self.news_collector_agent()
        )
    
    @task
    def collect_economy_news_task(self):
        task_config = self.tasks_config["collect_economy_news_task"].copy()
        task_config.pop("agent")
        return Task(
            **task_config,
            agent=self.news_collector_agent()
        )
    
    @task
    def summarize_politics_news_task(self):
        task_config = self.tasks_config["summarize_politics_news_task"].copy()
        task_config.pop("agent")
        return Task(
            **task_config,
            agent=self.news_summarizer_agent(),
            context=[self.collect_politics_news_task()]
        )
    
    @task
    def summarize_economy_news_task(self):
        task_config = self.tasks_config["summarize_economy_news_task"].copy()
        task_config.pop("agent")
        return Task(
            **task_config,
            agent=self.news_summarizer_agent(),
            context=[self.collect_economy_news_task()]
        )
    
    @crew
    def assemble_crew(self):
        return Crew(
            agents=[
                self.news_collector_agent(),
                self.news_summarizer_agent()
            ],
            tasks=[
                self.collect_politics_news_task(),
                self.collect_economy_news_task(),
                self.summarize_politics_news_task(),
                self.summarize_economy_news_task()
            ],
            verbose=True
        )


def escape_html(text: str) -> str:
    """HTML íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
    if not text:
        return ""
    return (text
            .replace('&', '&amp;')
            .replace('<', '&lt;')
            .replace('>', '&gt;')
            .replace('"', '&quot;')
            .replace("'", '&#39;'))


def generate_html_report(politics_summary: str, economy_summary: str, 
                         politics_news: List[Dict], economy_news: List[Dict]) -> str:
    """HTML ë³´ê³ ì„œ ìƒì„± (profileReport ìŠ¤íƒ€ì¼)"""
    
    # ì •ì¹˜ ë‰´ìŠ¤ ì¹´ë“œ HTML ìƒì„±
    politics_cards = ""
    for i, news in enumerate(politics_news[:5], 1):
        title = escape_html(news.get('title', 'ì œëª© ì—†ìŒ'))
        content = escape_html(news.get('content', 'ë³¸ë¬¸ ì—†ìŒ')[:200])
        date = escape_html(news.get('date', 'ë‚ ì§œ ì—†ìŒ'))
        link = escape_html(news.get('link', '#'))
        
        politics_cards += f"""
        <div class="news-card">
            <div class="news-header">
                <span class="news-number">#{i}</span>
                <span class="news-date">{date}</span>
            </div>
            <h3 class="news-title">{title}</h3>
            <p class="news-content">{content}...</p>
            <a href="{link}" target="_blank" class="news-link">ì›ë¬¸ ë³´ê¸° â†’</a>
        </div>
        """
    
    # ê²½ì œ ë‰´ìŠ¤ ì¹´ë“œ HTML ìƒì„±
    economy_cards = ""
    for i, news in enumerate(economy_news[:5], 1):
        title = escape_html(news.get('title', 'ì œëª© ì—†ìŒ'))
        content = escape_html(news.get('content', 'ë³¸ë¬¸ ì—†ìŒ')[:200])
        date = escape_html(news.get('date', 'ë‚ ì§œ ì—†ìŒ'))
        link = escape_html(news.get('link', '#'))
        
        economy_cards += f"""
        <div class="news-card">
            <div class="news-header">
                <span class="news-number">#{i}</span>
                <span class="news-date">{date}</span>
            </div>
            <h3 class="news-title">{title}</h3>
            <p class="news-content">{content}...</p>
            <a href="{link}" target="_blank" class="news-link">ì›ë¬¸ ë³´ê¸° â†’</a>
        </div>
        """
    
    html_template = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ë‰´ìŠ¤ ìš”ì•½ ë³´ê³ ì„œ</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            min-height: 100vh;
        }}
        
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }}
        
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
        }}
        
        .header p {{
            font-size: 1.1em;
            opacity: 0.9;
        }}
        
        .report-date {{
            margin-top: 15px;
            font-size: 0.9em;
            opacity: 0.8;
        }}
        
        .section {{
            padding: 40px;
            border-bottom: 1px solid #e0e0e0;
        }}
        
        .section:last-child {{
            border-bottom: none;
        }}
        
        .section-title {{
            font-size: 1.8em;
            color: #333;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid #667eea;
            display: flex;
            align-items: center;
            gap: 10px;
        }}
        
        .section-title::before {{
            content: '';
            width: 5px;
            height: 30px;
            background: #667eea;
            border-radius: 3px;
        }}
        
        .summary-box {{
            background: #f8f9fa;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin-bottom: 30px;
            border-radius: 5px;
            line-height: 1.8;
            color: #444;
            white-space: pre-wrap;
        }}
        
        .news-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }}
        
        .news-card {{
            background: white;
            border: 1px solid #e0e0e0;
            border-radius: 10px;
            padding: 20px;
            transition: transform 0.3s, box-shadow 0.3s;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }}
        
        .news-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.15);
        }}
        
        .news-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }}
        
        .news-number {{
            background: #667eea;
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 600;
        }}
        
        .news-date {{
            color: #666;
            font-size: 0.85em;
        }}
        
        .news-title {{
            font-size: 1.1em;
            color: #333;
            margin-bottom: 12px;
            line-height: 1.4;
            font-weight: 600;
        }}
        
        .news-content {{
            color: #666;
            font-size: 0.95em;
            line-height: 1.6;
            margin-bottom: 15px;
        }}
        
        .news-link {{
            color: #667eea;
            text-decoration: none;
            font-weight: 600;
            font-size: 0.9em;
            transition: color 0.3s;
        }}
        
        .news-link:hover {{
            color: #764ba2;
        }}
        
        .stats {{
            display: flex;
            justify-content: space-around;
            padding: 30px;
            background: #f8f9fa;
            border-top: 1px solid #e0e0e0;
        }}
        
        .stat-item {{
            text-align: center;
        }}
        
        .stat-number {{
            font-size: 2em;
            font-weight: 700;
            color: #667eea;
        }}
        
        .stat-label {{
            color: #666;
            margin-top: 5px;
            font-size: 0.9em;
        }}
        
        @media (max-width: 768px) {{
            .news-grid {{
                grid-template-columns: 1fr;
            }}
            
            .header h1 {{
                font-size: 1.8em;
            }}
            
            .section {{
                padding: 20px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“° ë‰´ìŠ¤ ìš”ì•½ ë³´ê³ ì„œ</h1>
            <p>ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ì¹˜/ê²½ì œ ë¶„ì•¼ ìµœì‹  ê¸°ì‚¬ ë¶„ì„</p>
            <div class="report-date">ìƒì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}</div>
        </div>
        
        <div class="stats">
            <div class="stat-item">
                <div class="stat-number">{len(politics_news[:5])}</div>
                <div class="stat-label">ì •ì¹˜ ê¸°ì‚¬</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">{len(economy_news[:5])}</div>
                <div class="stat-label">ê²½ì œ ê¸°ì‚¬</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">{len(politics_news[:5]) + len(economy_news[:5])}</div>
                <div class="stat-label">ì „ì²´ ê¸°ì‚¬</div>
            </div>
        </div>
        
        <div class="section">
            <h2 class="section-title">ğŸ›ï¸ ì •ì¹˜ ë‰´ìŠ¤ ìš”ì•½</h2>
            <div class="summary-box">{escape_html(politics_summary)}</div>
            <div class="news-grid">
                {politics_cards}
            </div>
        </div>
        
        <div class="section">
            <h2 class="section-title">ğŸ’° ê²½ì œ ë‰´ìŠ¤ ìš”ì•½</h2>
            <div class="summary-box">{escape_html(economy_summary)}</div>
            <div class="news-grid">
                {economy_cards}
            </div>
        </div>
    </div>
</body>
</html>
    """
    return html_template


def parse_task_result(result_str: str) -> tuple:
    """íƒœìŠ¤í¬ ê²°ê³¼ì—ì„œ ë‰´ìŠ¤ ë°ì´í„°ì™€ ìš”ì•½ ì¶”ì¶œ"""
    import json
    import ast
    
    # JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
    try:
        if isinstance(result_str, str):
            # JSON ë¬¸ìì—´ì¸ ê²½ìš°
            if result_str.strip().startswith('[') or result_str.strip().startswith('{'):
                try:
                    data = json.loads(result_str)
                    if isinstance(data, list):
                        return data, ""
                    elif isinstance(data, dict):
                        return data.get('news', []), data.get('summary', "")
                except:
                    pass
            
            # Python ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ ë¬¸ìì—´ì¸ ê²½ìš°
            try:
                data = ast.literal_eval(result_str)
                if isinstance(data, list):
                    return data, ""
                elif isinstance(data, dict):
                    return data.get('news', []), data.get('summary', "")
            except:
                pass
    except:
        pass
    
    return [], result_str


if __name__ == "__main__":
    # ë‰´ìŠ¤ ìˆ˜ì§‘ ê°œìˆ˜ ì„¤ì •
    num_articles = 5
    
    print("="*50)
    print("ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ìš”ì•½ ì‹œì‘...")
    print("="*50)
    
    # ì§ì ‘ ë‰´ìŠ¤ ìˆ˜ì§‘ (íƒœìŠ¤í¬ ì‹¤í–‰ ì „ì— ë°ì´í„° í™•ë³´)
    print("\n[1/2] ì •ì¹˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    politics_news = _collect_naver_news_impl("ì •ì¹˜", num_articles)
    print(f"   ìˆ˜ì§‘ëœ ì •ì¹˜ ë‰´ìŠ¤: {len(politics_news)}ê°œ")
    
    print("\n[2/2] ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    economy_news = _collect_naver_news_impl("ê²½ì œ", num_articles)
    print(f"   ìˆ˜ì§‘ëœ ê²½ì œ ë‰´ìŠ¤: {len(economy_news)}ê°œ")
    
    # ê° íƒœìŠ¤í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ìš”ì•½ ìƒì„±
    print("\n" + "="*50)
    print("ë‰´ìŠ¤ ìš”ì•½ ìƒì„± ì¤‘...")
    print("="*50)
    
    crew = NewsSummaryCrew()
    
    # ì •ì¹˜ ë‰´ìŠ¤ ìš”ì•½ ìƒì„±
    print("\n[1/2] ì •ì¹˜ ë‰´ìŠ¤ ìš”ì•½ ìƒì„± ì¤‘...")
    politics_collect_task = crew.collect_politics_news_task()
    politics_summarize_task = crew.summarize_politics_news_task()
    
    # ì •ì¹˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ìš”ì•½ì„ ìœ„í•œ ê°„ë‹¨í•œ Crew ìƒì„±
    politics_crew = Crew(
        agents=[crew.news_collector_agent(), crew.news_summarizer_agent()],
        tasks=[politics_collect_task, politics_summarize_task],
        verbose=False
    )
    politics_result = politics_crew.kickoff(inputs={"num_articles": num_articles})
    politics_summary = str(politics_result)
    
    # ê²½ì œ ë‰´ìŠ¤ ìš”ì•½ ìƒì„±
    print("\n[2/2] ê²½ì œ ë‰´ìŠ¤ ìš”ì•½ ìƒì„± ì¤‘...")
    economy_collect_task = crew.collect_economy_news_task()
    economy_summarize_task = crew.summarize_economy_news_task()
    
    economy_crew = Crew(
        agents=[crew.news_collector_agent(), crew.news_summarizer_agent()],
        tasks=[economy_collect_task, economy_summarize_task],
        verbose=False
    )
    economy_result = economy_crew.kickoff(inputs={"num_articles": num_articles})
    economy_summary = str(economy_result)
    
    # ìš”ì•½ì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±° ë° ì •ë¦¬
    import re
    
    # ì •ì¹˜ ìš”ì•½ ì •ë¦¬
    if "Final Answer" in politics_summary:
        # "Final Answer:" ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        final_answer_idx = politics_summary.find("Final Answer")
        if final_answer_idx >= 0:
            politics_summary = politics_summary[final_answer_idx:].split("Final Answer")[-1].strip()
            # ì•ë’¤ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
            politics_summary = re.sub(r'^[:\-\s]*', '', politics_summary)
            politics_summary = re.sub(r'[:\-\s]*$', '', politics_summary)
    
    # ê²½ì œ ìš”ì•½ ì •ë¦¬
    if "Final Answer" in economy_summary:
        # "Final Answer:" ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        final_answer_idx = economy_summary.find("Final Answer")
        if final_answer_idx >= 0:
            economy_summary = economy_summary[final_answer_idx:].split("Final Answer")[-1].strip()
            # ì•ë’¤ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
            economy_summary = re.sub(r'^[:\-\s]*', '', economy_summary)
            economy_summary = re.sub(r'[:\-\s]*$', '', economy_summary)
    
    # ë¹ˆ ìš”ì•½ ì²˜ë¦¬
    if not politics_summary or len(politics_summary.strip()) < 10:
        politics_summary = "ì •ì¹˜ ë‰´ìŠ¤ ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    if not economy_summary or len(economy_summary.strip()) < 10:
        economy_summary = "ê²½ì œ ë‰´ìŠ¤ ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    # HTML ë³´ê³ ì„œ ìƒì„±
    print("\nHTML ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    html_report = generate_html_report(
        politics_summary=politics_summary[:1000] if len(politics_summary) > 1000 else politics_summary,
        economy_summary=economy_summary[:1000] if len(economy_summary) > 1000 else economy_summary,
        politics_news=politics_news[:5],
        economy_news=economy_news[:5]
    )
    
    # HTML íŒŒì¼ ì €ì¥
    output_file = f"news_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html_report)
    
    print("\n" + "="*50)
    print("âœ… ì™„ë£Œ!")
    print("="*50)
    print(f"HTML ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
    print(f"ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ë³´ì„¸ìš”!")
    print(f"\nìˆ˜ì§‘ëœ ë‰´ìŠ¤:")
    print(f"  - ì •ì¹˜: {len(politics_news)}ê°œ")
    print(f"  - ê²½ì œ: {len(economy_news)}ê°œ")